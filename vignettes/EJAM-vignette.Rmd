---
title: "Basics of using EJAM in RStudio"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Basics of using EJAM in RStudio}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r SETUP_default_eval_or_not, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_chunk$set(eval = FALSE)
# https://r-pkgs.org/vignettes.html
```

```{r libraryEJAM, eval=TRUE, echo=FALSE, include=FALSE}
library(EJAM)
```

```{r developernote, echo=FALSE}
#
#  *>>>>>>>>>> Developer note on updating this vignette <<<<<<<<<<<*
#
#  -   *TO UPDATE THIS VIGNETTE:* 
#
#    - *This vignette must be regularly tested/edited*
#
#    - Do this...   rmarkdown::render("vignettes/EJAM-vignette.Rmd") 
#
#  -    See <https://docs.ropensci.org/postdoc/> for quick way to make html help on a pkg. Do this...   postdoc::render_package_manual('EJAM') 
#
#  -   *See <https://r-pkgs.org/vignettes.html#sec-vignettes-how-built>*
#
#  -   *Vignette is in EJAM\vignettes\EJAM-vignette.html*
```

# Quick start for the web app

## Trying out the EJAM web app

If you have not installed the R package, you can try a live demo version -- The complete version of the app is not on a server as of 10/2023, but a working demo of the most basic feature is on a staging server at [EJAM Lite (Demo/Test on Staging Server)](https://rstudio-connect.dmap-stage.aws.epa.gov/content/725e3761-3dc1-4012-b07c-23126063da97/ "https://rstudio-connect.dmap-stage.aws.epa.gov/content/725e3761-3dc1-4012-b07c-23126063da97/"){.uri target="_blank" rel="noreferrer noopener"}.

The EJAM R package and app are in active development. The latest current version can be installed from the github USEPA github repository. It can be installed locally as an R package, and the data or functions can be used even without launching the shiny app interface. This is work in progress, so not everything may be working as changes are made on the staging server or GitHub version.

Note that the demo app takes a long time (up to a full minute perhaps) to start up and load all the datasets and packages and then build an index. The analysis can be started only after the blue bar lights up to show that the spreadsheet with lat lon values has been uploaded.

# Quick start for R users

## Trying out the EJAM app or R functions in RStudio

EJAM is not only a web app built in shiny R, it is also an R package, using the [golem](https://thinkr-open.github.io/golem/ "https://thinkr-open.github.io/golem/"){.uri target="_blank" rel="noreferrer noopener"} framework.

### To install the EJAM R package and related packages

To install the latest development version of EJAM, you will first need to make sure you have access to the GitHub repositories on EPA's enterprise github site, at [USEPA GitHub](https://github.com/USEPA "https://github.com/USEPA"){.uri target="_blank" rel="noreferrer noopener"}. You need to use VPN or be inside the EPA LAN at the office.

If you just want to install it but not work with source code, use the following approach to install from internal repositories:

Try to install the packages using `devtools::install_github()` like this:

``` r
if (!require(devtools)) {install.packages("devtools")}
devtools::install_github('USEPA/EJAMejscreenapi')
devtools::install_github('USEPA/EJAMbatch.summarizer')
devtools::install_github('USEPA/EJAM')
```

If that does not work, you need to do the following:

1.  create GitHub personal access token with 'repo scope'

-   Go to [https://github.com/settings/tokens](https://github.com/settings/tokens){.uri target="_blank" rel="noreferrer noopener"} and select Tokens (classic) on the left-hand side. Then click 'Generate New Token' -\> Generate new token (classic).
-   Give it a name and select all boxes under repo scope. Scroll down and click 'Generate Token'.

2.  set GitHub credentials in Rstudio

-   one-time login: from the console, run credentials::set_github_pat(). Paste in your PAT to the login popup under 'Token'.
-   store credentials long-term: run usethis::edit_r\_environ() to open your .Renviron file and and add a line with your PAT in this format: GITHUB_PAT = 'abc'
    -   You can specify an extra argument scope = 'project' if you only want the PAT to work for a particular Rstudio project.

3.  Install the packages using `devtools::install_github()`

``` r
if (!require(devtools)) {install.packages("devtools")}
devtools::install_github('USEPA/EJAMejscreenapi')
devtools::install_github('USEPA/EJAMbatch.summarizer')
devtools::install_github('USEPA/EJAM')
```

Make sure you also have installed packages listed in the `DESCRIPTION` file of the R package. Then you can use EJAM in RStudio -- either as a web app running locally or as a set of useful functions in the RStudio console.

### To clone/ build/ install from source (for coders)

If you can see the repository and know how to clone and build/install from source, then you should be able to clone from EJAM's code repositories for internal EPA use:

Essential packages only available on the [USEPA github](https://github.com/USEPA/EJAM "github.com/USEPA/EJAM"){.uri target="_blank" rel="noreferrer noopener"} (not CRAN) are:

-   [EJAM](https://github.com/USEPA/EJAM#readme "github.com/USEPA/EJAM"){.uri target="_blank" rel="noreferrer noopener"}
-   [EJAMejscreenapi](https://github.com/USEPA/EJAMejscreenapi#readme "github.com/USEPA/EJAMejscreenapi"){.uri target="_blank" rel="noreferrer noopener"}
-   [EJAMbatch.summarizer](https://github.com/USEPA/EJAMbatch.summarizer#readme "github.com/USEPA/EJAMbatch.summarizer"){.uri target="_blank" rel="noreferrer noopener"}

Make sure you also have installed packages listed in the `DESCRIPTION` file of the R package. Then you can use EJAM in RStudio -- either as a web app running locally or as a set of useful functions in the RStudio console.

### Try the web app in RStudio

**run_app()** lets you launch the web app locally.

```{r run_app, eval=FALSE, include=TRUE}
library(EJAM)
run_app()
```
Note that the web app (e.g., launched locally) handles loading datasets and indexing blocks, so you would not have to use dataload_from_aws or indexblocks if launching the EJAM app locally.

### Initialize: load/attach package, download block data, build index

Once the packages are installed, to use EJAM in the console you can start by loading and attaching the package, using library or require. 

You can then load the datasets that are stored in AWS Data Commons during EJAM development. 

```{r library_dataload, eval=TRUE}
library(EJAM)

dataload_from_aws()
# It takes some time (maybe 30 to 60 seconds) for the large downloads, while EJAM is still in development.

indexblocks()
# It takes several seconds
# (or you can omit typing this since it would be run as needed once you try to use key functions)
```

You can save a little time if you first save those datasets locally and in later sessions have EJAM read them from your local drive instead of re-downloading from AWS.

```{r eval=FALSE}
help("dataload_from_local")  
```

Once you have loaded and indexed blocks, you can use EJAM. 

### Examples of points

EJAM comes with examples of points you can use to try things out, like `testpoints_10`
```{r eval=TRUE, fig.height=4.83, fig.width=3}
testpoints_10
mapfast(testpoints_100)
```
### Random points

You can create a set of random points with function `testpoints_n()` that can be weighted to represent the average resident, average regulated facility, etc.

```{r eval=TRUE}
pts <- testpoints_n(1000, weighting = 'blocks', ST_of_blockgroup = "LA")
mapfast(pts, radius = 0.1)
help("testpoints_n")
```

### Analyze and Map 100 Sites

```{r eval = TRUE, echo=TRUE}
x <- ejamit(testpoints_100, radius = 1) # 1 mile radius at 100 random points

# help("ejamit")

mapfastej(x$results_bysite)

# help("mapfast")
```

### Interactively select your file with lat,lon coordinates, without shiny web app

From RStudio, you can use EJAM functions to interactively select a file from your folders, to upload a spreadsheet or csv with columns called lat and lon in the first row as the header row, and then one row per point.

```{r eval=FALSE}
y <- read_csv_or_xl()
names(y)
head(y)
x <- ejamit(radius = 2) #  2 mile radius. 
```

### Specify all sites in 1 industrial sector

```{r eval = TRUE}
naics_from_any("paint and coating", children = T)
head(latlon_from_naics(325510)) # has about 1,000 facilities

## All sectors with this phrase in their NAICS title
#
#  x <- ejamit(frs_from_naics("paint and coating"), 1)
```

### Specify sites by facility registry ID

```{r frs_from_siteid, eval = FALSE}
frs_from_siteid(c(110071293460, 110000333826))

## interactively upload file with table of REGISTRY_ID values
x <- latlon_from_regid(read_csv_or_xl()$REGISTRY_ID)

## and run through EJAM
y <- ejamit(latlon_from_regid(read_csv_or_xl()$REGISTRY_ID), radius = 1)
#  # still debugging Island Areas validation here!

```

### Specify sites by facility ID (program system ID)

```{r eval = TRUE}
latlon_from_programid(c("XJW000012435", "00768SRTRSROAD1"))
```

### Specify sites by EPA regulatory program or EPA database

```{r eval = TRUE}
head(cbind(Count.of.facilities = sort(table(frs_by_programid$program), decreasing = T)), 20)

latlon_from_program("CAMDBS")[,1:6]
 
```

### Specify sites by EPA MACT Subpart in Clean Air Act

```{r eval = TRUE}
latlon_from_mactsubpart("OOOO")

nrow(latlon_from_mactsubpart("OOOO", include_if_no_latlon = FALSE))

nrow(latlon_from_mactsubpart("OOOO", include_if_no_latlon = TRUE))
```

## See Documentation of Functions and Data

See the readme for links to more documentation. There is documentation for the package overall, and individual functions and datasets.

```{r help, eval=FALSE, include=FALSE}
?EJAM
# or 
help("EJAM", package='EJAM')

?ejamit

```

## The EJScreen API module

The EJAMejscreen package was used to create a shiny module in EJAM that provides access to the EJScreen API in a loop or batch mode. It uses EJScreen to run reports on multiple places one at a time, so it is somewhat slow for more than a handful of places, but exactly replicates EJScreen results.

### Get EJScreen results in RStudio

In RStudio, you can use that code and app module like this:

```{r eval=FALSE}

# To interactively pick your own spreadsheet file from your local drive, that has lat and lon as two column headings and then one row per site:

x <- ejscreenit(radius = 1) # will prompt you for excel file with lat lon in it
```

```{r eval=FALSE}
x <- ejscreenit(data.frame(lon = c(-111,-113), lat = c(41,43)), radius = 2)
names(x)
x$map
x$table
ejscreenit_see_table(x)
```

### Get EJScreen results running a local web app \*\*\*not tested

```{r eval=FALSE}
### *** NOT TESTED - MAY NO LONGER WORK AS SHIFT TO USING MODULE VERSION
# If you have the local source package EJAMejscreenapi you can do this:
# setwd("YOUR PATH GOES HERE  EJAMejscreenapi")
library(EJAMejscreenapi)
EJAMejscreenapi::run_app()
```

### Get EJScreen results running a local web app module \*\*\*not tested

```{r api_module, eval=FALSE}
library(EJAMejscreenapi) 
library(shiny); library(magrittr); library(leaflet)  
# must attach all of those manually for this to work?
source(system.file("global.R", package = "EJAMejscreenapi"))
default_calculate_ratios <- TRUE
use_ejscreenit_tf <- FALSE
######################### #
  TEST_UI <- function(request) {
    shiny::fluidPage(
      tabsetPanel(
        tabPanel(
          title = "api app",
          shiny::h2('EJScreen API batch tool packaged with EJAM'), 
 # EJAM:::mod_ejscreenapi_ui("TESTID", simpleradius_default_for_ui = 2),
          mod_ejscreenapi_ui("TESTID", simpleradius_default_for_ui = 2),
          br()
        )))
    }
######################### #
  TEST_SERVER <- function(input, output, session) {
#x <- EJAM:::mod_ejscreenapi_server(
    x <-     mod_ejscreenapi_server(
      "TESTID", 
      default_points_shown_at_startup_react = reactive(testpoints_5[1:2,]),
      use_ejscreenit = use_ejscreenit_tf
    )
    output$testinfo2 <- renderText(
      cat("x names:  ", paste0(names(x()), collapse = ", "), "\n")
      )
    output$results <- DT::renderDataTable({x()}, 
      options = list(
        selection = 'multiple',
        dom = 'rtip', # specify 4 DOM elements: 
        # processing, table, info, pagination 
        # per https://datatables.net/examples/basic_init/dom.html
        scrollX = TRUE, 
        searchPanes = TRUE  # does this work?
      ),
      escape = FALSE 
    )
    # *** CAUTION ***
    # escape=TRUE is better for security reasons (XSS attacks).
    # escape=FALSE lets ejscreen URL links work, 
    #   but not links from ECHO table download.
  }
######################### #
  
shinyApp(ui = TEST_UI, server = TEST_SERVER) # Try module in mini/test app
```

## More ways of picking places to analyze in EJAM

### Specify points (where you want to center the circular buffers)

You can define locations as all residents within X miles of any one or more of the specified points, and you can define those points in a few ways. One way is to upload a table of coordinates -- latitude and longitude for each point, one row per site, with columns called lat and lon (or some synonyms that work).

The simplest way to do that in the RStudio console is to do something like x \<- ejamit(radius=1), and it prompts you to upload a spreadsheet with lat lon columns.

You can also specify a set of facilities by uploading their Registry ID numbers in a table, or using other identifiers. For example, there is a function latlon_from_programid().

You can define circular buffers around a set of EPA-regulated facilities in a few other ways as well, such as by NAICS (or SIC) industry names or codes, EPA program covering the set of facilities (e.g., all greenhouse gas reporters), or a Clean Air Act MACT subpart.

#### NAICS Codes to Map or Analyze Facilities in one Industrial Sector

Quick map of EPA-regulated facilities in one industrial category, which you can click on to see popup windows about sites.

```{r map1, eval = TRUE}
mapfast(frs_from_naics("smelt")) # may be slow the 1st time, if it lazyloads frs dataset
```

(but note that this FRS dataset lacks NAICS for most facilities!)

Table of facilities in an industry, plus links to each facility in ECHO and EJScreen

```{r, eval = FALSE}
industryword <- "chemical manuf"
#  industryword <- "smelt"

mysites <- frs_from_naics(industryword, children = FALSE)[,1:5]

regids <- mysites$REGISTRY_ID
link1 <- url_echo_facility_webpage(regids, as_html = T)
link2 <- url_ejscreen_report(lat = mysites$lat, lon = mysites$lon, radius = 3, as_html = T)
link3 <- url_ejscreenmap(lat = mysites$lat, lon = mysites$lon,  as_html = T)
link4 <- url_ejscreen_acs_report(lat = mysites$lat, lon = mysites$lon, radius = 3, as_html = T)
# # same:
# my_industry <- naics_from_any("chemical manuf",children = F)[,.(code,name)]
# mysites <- frs_from_naics(my_industry$code)[,1:5]
mysites <- cbind(`ECHO report` = link1, 
                 `EJScreen Report` = link2, `EJScreen Map` = link3, # `ACS Report` = link4,
                 mysites)
 caption = paste0(nrow(mysites), ' sites have NAICS matching "', industryword, '"')
if (nrow(mysites) > 1500) {mysites <- mysites[1:1500, ]} # >2k rows is too much for client-side DataTables
 cat(caption,'\n')

 print(
  DT::datatable(
    mysites,
    escape = FALSE,     rownames = FALSE,
    caption = caption,
    filter = "top"
  )[1:10, ]
)
```

Map of facilities in an industry, plus popups with links to each facility in ECHO and EJScreen

```{r map2, eval = FALSE}
mapfast(mysites)
```

NAICS/industry categories

```{r eval = TRUE}
naics_categories()
naics_from_any(naics_categories(3))[order(name),.(name,code)][1:10,]
naics_from_any(naics_categories(3))[order(code),.(code,name)][1:10,]

# See a data table of facilities in one industry
industryword <- "pulp"
head( frs_from_naics(naics_from_any(industryword)$code)[,1:4] )
```

Search using industry codes or text in industry names

```{r eval = TRUE}
naics_from_any("plastics and rubber") 

naics_from_any(326)

head(naics_from_any(326, children = T)[,.(code,name)])

naics_from_any("pig") 
naics_from_any("pig ") # space after g

# a OR b,  a AND b,  etc.
a = naics_from_any("plastics")

b = naics_from_any("rubber")

library(data.table)
data.table::fintersect(a,b)[,.(name,code)] #  a AND b

head(data.table::funion(a,b)[,.(name,code)])     #  a OR  b

naics_subcodes_from_code(funion(a,b)[,code])[,.(name,code)]   #  plus children

head(naics_from_any(funion(a,b)[,code], children = T)[,.(name,code)] ) #  same
```

A NAICS code can have many "children" or subcategories under it

```{r eval = TRUE}
NROW(naics_from_any("chem"))
# about 20
NROW(naics_from_any("chem", children = T))
# >100
NROW(frs_from_naics(naics_from_any("chem")$code))
# a few thousand
 NROW(frs_from_naics(naics_from_any("chem", children = T)$code))
# >10,000
```

#### Map of the blocks found near 1 site

```{r plotblocksnearby_1, eval = TRUE}
plotblocksnearby(testpoints_n(1), radius = 3)
```

#### Use lat/lon point data

Enter lat and lon to specify points

```{r sitepoints2, eval = TRUE}

sitepoints2  <- data.frame(
  lon = c(-92.1, -91.8), 
  lat = c(34.8799123, 30.2906971), 
  siteid = 1:2
)
```

Use lat/lon coordinates in a table like a spreadsheet - xlsx or csv file

The first row should be column names including lat and lon, or something that can be interpreted as that - see latlon_infer()

```{r writecsv, eval=FALSE, include=TRUE}
testjunk <- file.path(tempdir(), 'testjunk.csv')
write.csv(data.frame(LONG = c(-92.1, -91.8), Latitude = c(34.8, 30.2), siteid = 1:2), file = testjunk, row.names = FALSE)
sitepoints2 <- latlon_from_anything(testjunk)
sitepoints2
```

Use test points in examples that comes with the package

```{r testpoints, eval = TRUE, echo=TRUE}
testpoints_100 |> head(2) # data.table, in this package
sitepoints100 <- data.table::copy(testpoints_100)  # [1:5, ]
head(sitepoints100, 3)
```

Create random test data points in States of LA and TX

```{r mapfast_testpoints_n, eval = TRUE}
# ?testpoints_n
# p1k <- testpoints_n(1000)
# mapfast(p1k)

mapfast(testpoints_n(300, ST_of_blockgroup = c('LA','TX')) )
```

### Specify radius for circular buffer, and other key parameters

```{r eval = TRUE}
radius <- 3 # radius (in miles).  5 km = 3.1 miles, 10 km = 6.2 miles
```

### Key Functions in EJAM

-   **run_app()** to launch the web app locally

-   **ejamit()** provides results in just one function, by using getblocksnearby() and doaggregate():

-   **getblocksnearby()** takes a set of points (e.g., facilities) and finds the Census blocks near each. Sample input is in testpoints_100, and sample output is in testoutput_getblocksnearby_10pts_1miles

-   **doaggregate()** takes the list of blocks near each point, joins it to blockgroup indicators like from EJScreen, and aggregates at each buffered point as well as for the overall set of unique blocks (residents). Sample input is in testoutput_getblocksnearby_10pts_1miles

### Speed test

```{r speedtest, eval=FALSE, echo=TRUE, fig.height=3, fig.width=5}
speeds = EJAM::speedtest(n = 100, radii = c(1,3,5,6.2,10))
```

![](plot_speed_vs_radius.png){width="5in"}

### Use ejamit( ) to get results in one step

You can use x \<- ejamit(radius=1) with no dataset specified, in an interactive session in RStudio, and it will prompt you to specify a spreadsheet file with columns named lat and lon, for example. Specify the radius parameter in miles.

```{r speedreport, eval = TRUE}
## ejamit() just combines getblocksnearby() and doaggregate()
sitepoints <- testpoints_1000
# elapsed <- system.time({
began = Sys.time()
  out2 <- ejamit(
    sitepoints =  sitepoints  ,
    radius = radius
  )
  speedreport(began, Sys.time(), n = NROW(sitepoints))
# })
# print(elapsed)
```

Explore results in map and table

```{r seeresults, eval = TRUE}
names(out2)
cbind(as.list(out2$results_overall))
cbind(overall = as.list( out2$results_overall[ , ..names_d]))
cbind(overall = as.list( out2$results_overall[ , ..names_d_subgroups]))

## Site by site results in map or table:
 
# mapfast(out2$results_bysite, radius = radius)

DT::datatable(out2$results_bysite, escape = FALSE, rownames = FALSE)

```

### Specify Places or Shapes

#### Polygons in shapefiles as the places to compare

You can upload polygons in a shapefile, and use EJAM to analyze them. See the Shiny app.

#### Counties as the places to compare - DEBUGGING STILL

You can compare places defined by FIPS code, such as a group of US Counties.

```{r counties_fips, eval=FALSE}
# Compare all Counties in a State, using EJAM indicators

mystate <- "Delaware"
fips_counties_from_statename(mystate)

# debugging still...
# x <- ejamit(fips = fips_counties_from_statename(mystate)) # radius not used

#round(t(x$results_summarized$rows)[,1:6],2)
#t(x$results_bysite[ , c(
#  'siteid', 'pop', names_d_subgroups_ratio_to_state_avg), with = F])
#
#mapfast(x$results_bysite, 
#        column_names = c(
#  'siteid', 'pop', names_d_subgroups_ratio_to_state_avg), 
#        labels = c(
#          'FIPS', 'Pop', names_d_subgroups_ratio_to_state_avg_friendly))

#x$results_bysite$ratio.to.avg.Demog.Index

 
# cnames <- get.county.info(x$results_bysite$siteid)$countyname
#cnames <- c("Kent County", "New Castle County", "Sussex County")
#cnames <- gsub(" County", "", cnames)

#barplot(x$results_bysite$pctlowinc, names.arg = cnames, 
#        main = paste0('% Low Income by County in ', mystate))

# Another example
#mystate <- "Maryland"
#vname <- "% low income"
#xmd <- ejamit(fips = fips_counties_from_statename(mystate))
#ggblanket::gg_col(data = xmd$results_bysite,
#                  y = pctlowinc,
#                  x = siteid, 
#                  title = paste0(vname, ' by County in ', mystate),
#                  y_title = vname
#                  )
```

### Get granular results step by step, and view details

#### getblocksnearby() will find residents/blocks that are within specified distance

About \< 1 second for 100 sites, but a few seconds for 1,000 sites, or roughly 500k / hour for this step

```{r getblocksnearby1, eval=FALSE}
sitepoints <- data.table::copy(testpoints_100) 
# or 
# sitepoints <- testpoints_n(100,"block") # random points
radius <- 3
elapsed <- system.time({
  
  sites2blocks <- getblocksnearby(
    sitepoints = sitepoints,
    radius = radius
  )
  
}) # end of timed function
print(elapsed)
sites2blocks
```

#### Map of the blocks found near 1 site (again)

```{r plotblocksnearby, eval = TRUE}
plotblocksnearby(testpoints_n(1), radius = 3)
```

#### View detailed diagnostics or stats on the intermediate result:

-   what blocks are near each site
-   how far are they
-   how many blocks are typically near a given site (population density varies a lot)
-   how many sites are near a block (residents who have more than 1 site near them)

```{r getblocksnearby2, eval = TRUE}
## Also could use this example intermediate step dataset 
## of n sites, with thousands of nearby blocks:
# sites2blocks <- data.table::copy(testoutput_getblocksnearby_10pts_1miles)
sitepoints <- data.table::copy(testpoints_100) 
sites2blocks <- getblocksnearby(sitepoints, radius, quadtree = localtree)
names(sites2blocks)
getblocks_summarize_blocks_per_site(sites2blocks) # print() shows more info returned invisibly
getblocks_diagnostics(sites2blocks)
# Use data.table package here
library(data.table)
# Very few blocks are within a radius of 1/4 mile.
# Hundreds are often within 1 mile, but sometimes there are only a handful or even zero.
s2b_stats <- sites2blocks[ , .(
  avgDistance = round(mean(distance), 2),
  blocksfound = .N, 
  blocks_within_1mile = sum(distance <= 1),
  blocks_within_0.75   = sum(distance <= 0.75),
  blocks_within_0.25  = sum(distance <= 0.25)
), by = 'siteid'][order(blocksfound), ]
setorder(s2b_stats, siteid)
head(s2b_stats)

```

```{r plot_count_of_blocks_nearby, eval = TRUE}

# CDF of how many blocks are nearby a site
plot(sort(s2b_stats$blocks_within_1mile), 
     main = "How many blocks are near each facility?", 
     ylab = "# of blocks (whose internal point is) within 1 mile of each facility", 
     xlab = paste0(nrow(s2b_stats), " facilities ranked by # of blocks nearby"))
abline(h = quantile(s2b_stats$blocks_within_1mile, probs = (0:4) * 0.25))
abline(h = mean(s2b_stats$blocks_within_1mile), col = "red")


```

```{r histoblocks, eval = TRUE}
# Histogram of how many blocks are nearby a site
hist(sites2blocks[,.N,by = "siteid"][,N],20, 
     xlab = "How many blocks are nearby?", 
     ylab = "Frequency (# of sites)", 
     main = "A given site may have zero to hundreds of blocks nearby", 
     sub = "A typical site in this example has about 100 blocks nearby")
```

```{r DTdatatable, eval = FALSE}

DT::datatable(s2b_stats,  rownames = FALSE)
# more summaries showing there may be only 1 block or several hundred blocks within 1 mile
quantile(s2b_stats$blocks_within_1mile, probs = (0:4) * 0.25)
t(summary(s2b_stats))
```

```{r s2b_stats, eval = TRUE}
# map the sites with popups about how many blocks were found near each
if (!('siteid' %in% names(sitepoints))) {sitepoints$siteid <- seq.int(length.out = NROW(sitepoints))}
s2b_stats <- merge(sitepoints, s2b_stats, by = "siteid")
mapfast(s2b_stats, radius = radius)
```

```{r eval = TRUE}
# A 1 mile radius is huge within a dense urban area
mapfast(s2b_stats[87:88,], radius = radius)
```

```{r eval = TRUE}
# Within a 1 mile radius, the blocks found tend to be about 2/3 of a mile from the site at the center.
summary(s2b_stats$avgDistance)
```

#### doaggregate() will summarize indicators within each buffer and overall

```{r doaggregate, eval = TRUE}
# out <- doaggregate(testoutput_getblocksnearby_10pts_1miles)

elapsed <- system.time({
  out <- suppressWarnings( 
    doaggregate(sites2blocks = sites2blocks) 
  )
}) 
print(elapsed)

names(out)
dim(out$results_bysite)
```

#### See indicators aggregated over all people across all sites

```{r eval = TRUE}
## view output of batch run aggregation ####
cbind(overall = as.list( out$results_overall))

## To see just some subset of indicators, like Environmental only:
cbind(overall = as.list( out$results_overall[ , ..names_e]))
cbind(overall = as.list( out$results_overall[ , ..names_d]))
cbind(overall = as.list( out$results_overall[ , ..names_d_subgroups]))
cbind(overall = as.list( out$results_overall[ , ..names_e_pctile]))
cbind(overall = as.list( out$results_overall[ , ..names_d_pctile]))
# cbind(overall = as.list( out$results_overall[ , ..names_ej_pctile]))
```

#### Histogram of indicators distribution over all people across all sites

```{r histo, eval = TRUE}
hist(out$results_bysite$pctile.traffic.score, 10, xlab = "Local traffic scores (expressed as a percentile)", 
     ylab = "count of sites in each bin, out of 1,000 sites", freq = TRUE, 
     main = "Actual distribution of indicators nearby, as percentiles, vs flat line = USA overall")
abline(h = nrow(out$results_bysite)/10)
```

#### Compare to results from EJScreen API

```{r eval = FALSE}
sitepoints <- testpoints_1000 
radius <- 1

# outapi2 <- ejscreenapi_plus(sitepoints[1:5, ], radius = radius, on_server_so_dont_save_files = T)

## SLOW
# outapi <- (ejscreenit(sitepoints[1:5, ], 
#                      radius = radius, 
#                      nosave = T, nosee = T, 
#                      interactiveprompt = F))$table
#
#cbind(as.list(outapi[1, ]))

outejam <- ejamit(sitepoints =  sitepoints[1:5, ], radius = radius)

#setdiff( names(outapi), names(outejam$results_overall))
cat("----------------\n")
#setdiff_yx( names(outapi), names(outejam$results_overall))


# links to report or map were named differently.
#  
# EJ pctiles, etc. might not be provided in EJAM output.   
```
