---
title: "Basics of using EJAM in RStudio"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Basics of using EJAM in RStudio}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_chunk$set(eval = FALSE)
# https://r-pkgs.org/vignettes.html
```

## *Developer note on building and updating this vignette*

See important info at <https://r-pkgs.org/vignettes.html#sec-vignettes-how-built>

## Accessing and using the code/ data/ app

The app is not on a server. The R package is still in active development, but a current version can be installed from the github USEPA github repository. It can be installed locally as an R package, and the data or functions can be used even without launching the shiny app interface. This is work in progress - only the lat/lon upload may be working right now, for example, not the NAICS/FRS queries.

## Installing EJAM

You can install the development version of EJAM like so:

``` r
if (!require(EJAM)) {
if (!require(devtools)) {install.packages('devtools')}
devtools::install_github('USEPA/EJAM')
}
```

## See the [README](https://github.com/USEPA/EJAM#readme "github.com/USEPA/EJAM#readme") if you need a basic intro and broad overview

You can find it here: <https://github.com/USEPA/EJAM#readme>

## Run the Shiny app on your own computer, in RStudio

Launch the web app with run_app() instead of shiny's runApp() because this shiny app is also an R package based on the golem package framework.

```{r run_app}
run_app()
```

## Documentation of functions and data

See this vignette and help documentation for the package overall, and individual functions and datasets.

```{r help, eval=FALSE, include=FALSE}
help("EJAM", package='EJAM')
```

## **Get proximity analysis via R script or console**

### Install other R packages

Relevant or essential packages only available on the [USEPA github](https://github.com/USEPA/EJAM "github.com/USEPA/EJAM") (not CRAN) are:

-   [EJAM](https://github.com/USEPA/EJAM#readme "github.com/USEPA/EJAM")
-   [EJAMblockdata](https://github.com/USEPA/EJAMblockdata#readme "github.com/USEPA/EJAMblockdata#readme")
-   [EJAMfrsdata](https://github.com/USEPA/EJAMfrsdata#readme "github.com/USEPA/EJAMfrsdata")
-   [EJAMejscreendata](https://github.com/USEPA/EJAMejscreendata#readme "github.com/USEPA/EJAMejscreendata")
-   [EJAMejscreenapi](https://github.com/USEPA/EJAMejscreenapi#readme "github.com/USEPA/EJAMejscreenapi")
-   [EJAMbatch.summarizer](https://github.com/USEPA/EJAMbatch.summarizer#readme "github.com/USEPA/EJAMbatch.summarizer")

```{r install_others}
if (!require(EJAM)) {
  if (!require(devtools)) {install.packages('devtools')}
  devtools::install_github('USEPA/EJAM')
}
if (!require(data.table)) {install.packages('data.table')}
# These and other required should get installed and loaded and attached by EJAM 
#   library(EJAMblockdata)
#   library(EJAMfrsdata) ## EPA Facility Registry Service data for lat/lon of each regulated site
```

### Create the index of where blocks are, to be able to quickly find those nearby a given site

IMPORTANT NOTE: During development of this package, at least, this index is built when the package is loaded, automatically, by the .onLoad() function in the file EJAM/R/aaa_onLoad_create_quad_tree_index.R 
THIS IS SLOW - It takes a few seconds. This (seemingly) must be done for each session? One cannot save it as .rda and just load via a pkg since it is like a pointer to the index in RAM or something like that.

```{r BUILD_INDEX}
# One could manually rebuild the index (if quaddata were updated, for example),
#  like this:
system.time({
  localtree <- SearchTrees::createTree(
    EJAMblockdata::quaddata, treeType = "quad", dataType = "point"
  )
})
```

### Specify points (where you want to center the circular buffers)

#### Name an Industrial Sector & Map those EPA-regulated Facilities

```{r}
# See a data table of facilities in one industry
industryword <- "pulp"
mysites <- EJAMfrsdata::frs[EJAMfrsdata::frs$REGISTRY_ID %chin% unlist(
  EJAMfrsdata::get_siteid_from_naics(
    EJAM::NAICS_find(industryword, add_children = FALSE))[,"REGISTRY_ID"]), 1:5]

DT::datatable(
  mysites, 
  caption = paste0("FACILITIES WITH NAICS MATCHING QUERY TERM ", industryword), filter = "top"
)

# See a map of one industry

sitepoints1 <- EJAMfrsdata::frs[EJAMfrsdata::frs$REGISTRY_ID %chin% unlist(
    EJAMfrsdata::get_siteid_from_naics(
      EJAM::NAICS_find(industryword, add_children = TRUE))[,"REGISTRY_ID"]),  ]
EJAMejscreenapi::mapfast(sitepoints1)
nrow(sitepoints1)
```

#### Use lat and lon to specify points

```{r}
sitepoints  <- data.frame(
  lon = c(-92.1, -91.8), 
  lat = c(34.8799123, 30.2906971), 
  siteid = 1:2
)
```

#### Use point data you read from a file

You can use lat lon coordinates from an xlsx or csv file. The first row should be column names including lat and lon, or something that can be interpreted as that - see latlon_infer()

```{r eval=FALSE, include=TRUE}
testjunk <- file.path(tempdir(), 'testjunk.csv')
write.csv(data.frame(LONG = c(-92.1, -91.8), Latitude = c(34.8, 30.2), siteid = 1:2), file = testjunk)
sitepoints3 <- latlon_readclean(testjunk)
```

#### Use test points example that comes with the package

```{r testpoints, eval=TRUE, include=TRUE}
EJAM::testpoints_100_dt |> head(2) # data in this package
sitepoints4 <- data.table::copy(EJAM::testpoints_100_dt)  # [1:5, ]
head(sitepoints4, 3)
```

### Specify radius for circular buffer, and other key parameters

```{r}
radius <- 1 # radius (miles).  5 km = 3.1 miles, 10 km = 6.2 miles
```

### Note these Key Functions

-   **getblocksnearby_and_doaggregate()** provides results in just one function.

-   **getblocksnearby()** takes a set of points (e.g., facilities) and finds the Census blocks near each.

-   **doaggregate()** takes the list of blocks near each point, joins it to blockgroup indicators like from EJScreen, and aggregates at each buffered point as well as for the overall set of unique blocks (residents).

### Get results in one step

```{r}
## This function just combines getblocksnearby() and doaggregate()
elapsed <- system.time({
   out2 <- getblocksnearby_and_doaggregate(
     sitepoints =  sitepoints,
     cutoff = radius,
     quadtree = localtree
   )
})
print(elapsed)

```

### Get results step by step, and view details

#### getblocksnearby() will find residents/blocks that are within specified distance

About \< 1 second for 100 sites, but a few seconds for 1,000 sites, or roughly 500k / hour for this step

```{r}
elapsed <- system.time({
  
  sites2blocks <- EJAM::getblocksnearby(
    sitepoints = sitepoints,
    cutoff = radius,
    quadtree = localtree
  )
  
}) # end of timed function
print(elapsed)
```

#### View some diagnostics or stats on the intermediate result:

-   what blocks are near each site
-   how far are they
-   etc.

```{r}
## can use this example intermediate step dataset 
## of 99 sites, with 11,567 nearby blocks:
# sites2blocks_example
# sites2blocks <- data.table::copy(sites2blocks_example)
names(sites2blocks)
summarize_blocks_per_site(sites2blocks) # print() shows more info returned invisibly
summarize_sites_per_block(sites2blocks) # print() shows more info returned invisibly
summarize_blockcount(sites2blocks)
# Use data.table package here:
s2b_stats <- sites2blocks[ , .(
  avgDistance = round(mean(distance), 2),
  blocksfound = .N, 
  blocks_within_1mile = sum(distance <= 1),
  blocks_within_0.75   = sum(distance <= 0.75),
  blocks_within_0.25  = sum(distance <= 0.25)
), by = 'siteid'][order(blocksfound), ]
setorder(s2b_stats, siteid)
head(s2b_stats)

if (!('siteid' %in% names(sitepoints))) {sitepoints$siteid <- seq.int(length.out = NROW(sitepoints))}
s2b_stats <- merge(sitepoints, s2b_stats, by = "siteid")
mapfast(s2b_stats)
mapfast(s2b_stats[87:88,])
s2b_stats[,PGM_SYS_ACRNMS := NULL] # remove verbose column
DT::datatable(s2b_stats)

quantile(s2b_stats$blocks_within_1mile, probs = (0:4)* 0.25)
t(summary(s2b_stats)) 

plot(sort(s2b_stats$blocks_within_1mile), main="How many blocks are near each facility?", ylab="# of blocks (whose internal point is) within 1 mile of each facility", xlab=paste0(nrow(s2b_stats), " facilities ranked by # of blocks nearby"))
abline(h=quantile(s2b_stats$blocks_within_1mile, probs = (0:4)* 0.25))
abline(h=mean(s2b_stats$blocks_within_1mile), col="red")

# See how each site is surrounded by block points
x <- merge( sites2blocks, blockpoints )
setnames(x, 'lat', 'blocklat')
setnames(x, 'lon', 'blocklon')
x <- merge(sitepoints, x, by = "siteid")
x[,PGM_SYS_ACRNMS := NULL]
x
bplot=function(x,n) {plot(x$blocklon[x$siteid==n], x$blocklat[x$siteid==n] ); points(x$lon[x$siteid==n], x$lat[x$siteid==n] , col="red")}
bplot(x, sample(1:nrow(sitepoints),1)) # pick one of the sites and plot the site surrounded by block points

```

#### doaggregate() will summarize indicators within each buffer and overall

```{r}
# out <- doaggregate(sites2blocks_example)

elapsed <- system.time({
  out <- suppressWarnings( 
    
    doaggregate(sites2blocks = sites2blocks) 
    
  )
}) 
print(elapsed)

names(out)
dim(out$results_bysite)
```

#### See indicators aggregated over all people across all sites

```{r}
# cbind(prettyNum((out$results_overall[ , ..names_all])))

## To see just some subset of indicators, like Environmental only:
# cbind(prettyNum((out$results_overall[ , ..names_e])))
# cbind(prettyNum((out$results_overall[ , ..names_d])))
# cbind(prettyNum((out$results_overall[ , ..names_d_subgroups])))
# cbind(prettyNum((out$results_overall[ , ..names_e_pctile])))
# cbind(prettyNum((out$results_overall[ , ..names_d_pctile])))
# cbind(prettyNum((out$results_overall[ , ..names_ej_pctile])))

## view output of batch run aggregation ####
# cbind(prettyNum((out$results_overall))) 
names(out$results_)
```

-   *note: Demographic subgroups are not in the lookup tables of percentiles yet.*

-   *note: state.pctile indicators are all NA values so far until the State percentiles data is added to blockgroupstats*

# TO BE CONTINUED
