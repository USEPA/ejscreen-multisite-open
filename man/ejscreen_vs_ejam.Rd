% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ejscreen_vs_ejam_.R
\name{ejscreen_vs_ejam}
\alias{ejscreen_vs_ejam}
\title{EJAM/EJSCREEN comparisons}
\usage{
ejscreen_vs_ejam(
  latlon,
  radius = 3,
  fips = NULL,
  nadrop = FALSE,
  save_ejscreen_output = "ejscreenapi_plus_out.rda",
  save_when_report = FALSE,
  report_every_n = 250,
  calculate_ratios = FALSE,
  include_ejindexes = TRUE,
  x100fix = TRUE,
  x100varnames = names_pct_as_fraction_ejamit,
  ...
)
}
\arguments{
\item{latlon}{data.table or data.frame with colnames lat and lon,
and one row per site}

\item{radius}{in miles, used in ejamit() and ejscreenapi_plus()}

\item{fips}{FIPS code(s) of counties or blockgroups, if not using latlon and radius.}

\item{save_ejscreen_output}{set to NULL to avoid saving ejscreen results locally.
If specified as a valid path and filename ending in .rda, it saves there.
If missing, function will prompt in interactive R session
for a folder to use for saving the .rda results of ejscreenapi_plus().}

\item{save_when_report}{see \code{\link[=ejscreenapi_plus]{ejscreenapi_plus()}}, to save progress every so often just in case.}

\item{report_every_n}{see ejscreenapi_plus()}

\item{calculate_ratios}{passed to ejscreenapi_plus() and \code{\link[=ejamit]{ejamit()}}}

\item{x100fix}{whether to multiply x100 in ejamit() outputs the names_d and names_d_subgroups
indicator scores to convert fractions 0 to 1 into percentages of 0 to 100,
prior to rounding and reporting EJAM results here.}

\item{x100varnames}{optional, if x100fix = TRUE, a vector of colnames of x$EJAM to convert from
being scaled as 0 to 1 into rescaled values of 0 to 100, because some
outputs of EJSCREEN were reported as percentages 0 to 100 but as 0 to 1 in EJAM.}

\item{...}{passed to ejamit() as any additional parameters,
like include_ejindexes = FALSE}
}
\value{
a list of data frames, with names
EJSCREEN, EJAM, EJSCREEN_shown, EJAM_shown, same_shown,
ratio, diff, absdiff, pctdiff, abspctdiff

diff is EJAM - EJSCREEN

ratio is EJAM / EJSCREEN

pctdiff is ratio - 1

abs is absolute value

For each data.frame, colnames are indicators like pop, blockcount_near_site, etc.
and rows represent sites analyzed.
}
\description{
This is the main function that facilitates comparing
EJScreen API vs EJAM stats near site(s)
}
\details{
Note that the EJAM tool/ function called \code{\link[=ejamit]{ejamit()}}
does not rely on EJScreen to do the calculations
and instead tries to replicate what EJScreen would do.
As a result, as of early 2024 at least, while
\itemize{
\item \emph{\code{\link[=ejamit]{ejamit()}} is much, much faster than \code{\link[=ejscreenit_for_ejam]{ejscreenit_for_ejam()}}} and
\item \emph{provides additional information} (distribution of distances by group, etc.)
\item \emph{features} (histograms, spreadsheet with heatmaps, etc.)
\item \emph{flexibility} (easy for analysts using R to customize analysis, etc.),
\emph{\code{\link[=ejamit]{ejamit()}} does not always exactly replicate EJScreen} --
does not provide 100\% identical results (percentiles, etc.) for
every indicator in every analysis at every location.
This is due to slight variations in
\item details of the spatial calculations (which blocks are nearby,
sometimes counting 1 extra block as 2.99 miles away while
EJScreen counts it as outside the 3 mile radius, e.g.)
\item rounding (how many digits are retained during calculations,
and how many are shown in final reports)
\item percentile assignment method (how percentile lookup tables are used,
how ties are treated in percentile lookup tables, etc.), or
\item weighted averages or other formulas used for aggregation of blockgroup scores
(being updated in 2024 to more precisely match the formulas EJScreen uses)
}
}
\examples{
 \dontrun{
 # in RStudio, interactive:
 vs <- ejscreen_vscript()
 
 pts <- testpoints_100[1:5, ]
   
  # This step can take a long time, 
  # almost 1 minute / 20 points, as it uses the EJScreen API:
  #z <- ejscreen_vs_ejam(
    testpoints_100[27, ], radius = 3, nadrop = T, include_ejindexes = TRUE)
  z <- ejscreen_vs_ejam(pts, radius = 3, include_ejindexes = TRUE)
  
  EJAM:::ejscreen_vs_ejam_summary(z)
  
  # see one site
  ejscreen_vs_ejam_see1(z, mysite = 1)
  
   # Reported key indicators - which ones do or don't match
   # when comparing EJSCREEN and EJAM results?
   keyreportnames <- c('pop', names_these, 
     paste0('pctile.', c(names_these, names_ej, names_ej_supp)), 
     paste0('state.pctile.', c(names_these, names_ej, names_ej_supp))
   )
   z$EJAM[z$EJAM$rname \%in\% keyreportnames &  z$same_shown, ]
   z[z$rname \%in\% keyreportnames & !z$same_shown & !is.na(z$EJSCREEN), ]
  
   # Reported (rounded) numbers match:
   z[z$same_shown , -1]
   # Reports disagree: 
   #  (and not just because of percentages being of 100 vs of 1.00)
   z[!z$same_shown & !is.na(z$EJSCREEN) & z$ratio != 0.01, -1] 
   # Reports disagree if percentages reported as 0-100 vs fractions 0-1.00
   z[z$ratio == 0.01 & !is.na(z$ratio), -1]
   
  }
}
\seealso{
\code{\link[=ejscreen_vs_ejam_alreadyrun]{ejscreen_vs_ejam_alreadyrun()}}
}
\keyword{internal}
